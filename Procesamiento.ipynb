{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852f9258",
   "metadata": {},
   "source": [
    "# PROCESAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f950e",
   "metadata": {},
   "source": [
    "### 01 Importación de paquetes a usar e iniciación de H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2OTargetEncoderEstimator\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score, train_test_split\n",
    "import time\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3706027",
   "metadata": {},
   "source": [
    "### 02 Procesamiento Dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "go=pd.read_csv(\"../input/datos-prefinal-csv/datos_prefinal.csv\")\n",
    "go2=pd.read_csv(\"../input/datos-prefinal-csv/datos_prefinal.csv\")\n",
    "go2=go2.drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "# Asignamos NAN a los valores futuros (mayores al 2022-05-01)\n",
    "def dateNA(dataframe,column_name):\n",
    "    mask=pd.to_datetime(dataframe[column_name])>pd.Timestamp(\"2022-05-01\")\n",
    "    dataframe.loc[mask,column_name]=np.nan\n",
    "       \n",
    "dateNA(go2,\"FECINGRESOCLIENTE\")\n",
    "dateNA(go2,\"FECACTIVACIONCONTRATO\")\n",
    "dateNA(go2,\"LANZAMIENTO\") \n",
    "\n",
    "# Transformamos las fechas para que reflejen la antigüedad en meses\n",
    "def change_to_antiquity_month(dataframe, column_name):\n",
    "    dataframe[column_name]=round((pd.Timestamp.today()-pd.to_datetime(dataframe[column_name])) / np.timedelta64(1, 'M'),1)\n",
    "    \n",
    "change_to_antiquity_month(go2,\"FECINGRESOCLIENTE\")\n",
    "change_to_antiquity_month(go2,\"FECACTIVACIONCONTRATO\")\n",
    "change_to_antiquity_month(go2,\"LANZAMIENTO\")\n",
    "\n",
    "# Expresamos la variable Tipo_ADQ en dos columnas dummies\n",
    "a=pd.get_dummies(go2[\"TIPO_ADQ\"])\n",
    "a.rename(columns={1:\"Tipo_1\",2:\"Tipo_2\"},inplace=True)\n",
    "go2=pd.concat([go2, a], axis=1)\n",
    "go2.drop(\"TIPO_ADQ\",axis=1,inplace=True)\n",
    "\n",
    "# Generamos una variable tráfico_suma como la suma de las variables tráficos del 3 al 9\n",
    "go2[\"traf_sum\"]=0\n",
    "for i in range(3,10):\n",
    "    go2[\"traf_sum\"]+=go2[\"trafico_app_\"+str(i)]\n",
    "    \n",
    "# Una vez sumados los dropeamos\n",
    "for i in range(3,10):\n",
    "  go3=go3.drop(\"trafico_app_\"+str(i),axis=1)\n",
    "    \n",
    "# Seleccionamos las variables a escalar   \n",
    "escalar=[\"FECINGRESOCLIENTE\",\"FECACTIVACIONCONTRATO\",\"LANZAMIENTO\",\"VCHMESADENDA\",\"trafico_app_1\",\"trafico_app_2\",\"traf_sum\",\"trafico_total\",\"GIGAS\",\"MINUTOS\",\"MENSAJES\",\"mins_flujo_1\",\"mins_flujo_2\",\"VCHPENALIDAD\"]\n",
    "transformer = RobustScaler(quantile_range=(25.0, 75.0))\n",
    "go2[escalar]=transformer.fit_transform(go2[escalar])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expresamos NAN como -999 (para identificarlos con el algoritmo)\n",
    "go3=pd.DataFrame()\n",
    "for column in go2.columns.tolist():\n",
    "    go3[column] = go2[column].fillna(-999)\n",
    "\n",
    "# Expresamos el número de periodo como 1-4\n",
    "for i in range(0,5):\n",
    "  go3[\"NUMPERIODO\"].replace(202200+i,i,inplace=True)\n",
    "\n",
    "# Separamos los datos de entrenamiento y validación:\n",
    "Modelo=go3[go3[\"NUMPERIODO\"]!=4]\n",
    "Prueba=go3[go3[\"NUMPERIODO\"]==4]\n",
    "\n",
    "# Dropeamos el número de periodo\n",
    "Modelo=Modelo.drop(\"NUMPERIODO\",axis=1)\n",
    "Prueba=Prueba.drop(\"NUMPERIODO\",axis=1)\n",
    "\n",
    "# Trasformamos el dataframe de pandas a un dataframe de h2o, para aplicar con ese paquete un target (mean) encoding \n",
    "hf = h2o.H2OFrame(Modelo)\n",
    "hf[\"TARGET\"] = hf[\"TARGET\"].asfactor()\n",
    "\n",
    "rf = h2o.H2OFrame(Prueba)\n",
    "rf[\"TARGET\"] = rf[\"TARGET\"].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4261bce",
   "metadata": {},
   "source": [
    "### 03 Mean Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las variables cualitativas en las cuales usaremos el mean encoding \n",
    "from h2o.estimators import H2OTargetEncoderEstimator\n",
    "encoded_columns = [\"MARCA\",\"MODELO\",\"NUEVA_GAMMA\",\"OS\",\"DEVICE_TYPE\",\"GIRO\",\"SUBGIRO\"]\n",
    "\n",
    "hf[\"fold\"] = hf.kfold_column(n_folds=5, seed=25)\n",
    "\n",
    "# Para el mean encoding usamos un k-fold de 5 divisiones e introducimos ruido blanco para prevenir overfit\n",
    "te = H2OTargetEncoderEstimator(\n",
    "    data_leakage_handling = \"k_fold\",\n",
    "    fold_column = \"fold\",\n",
    "    noise = 0.02,\n",
    "    blending = True,\n",
    "    inflection_point = 10,\n",
    "    smoothing = 20)\n",
    "\n",
    "te.train(x = encoded_columns, y = \"TARGET\",\n",
    "    training_frame = hf)\n",
    "\n",
    "# Transformamos el dataset de prueba y testeo (este último, sin ruido blanco)\n",
    "train_te = te.transform(frame = hf)\n",
    "test_te = te.transform(frame = rf, noise = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96007689",
   "metadata": {},
   "source": [
    "### 04 Modelo y Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos a pandas y dropeamos las columnas originales:\n",
    "Modelo = train_te.as_data_frame()\n",
    "Prueba = test_te.as_data_frame()\n",
    "\n",
    "Modelo=Modelo.drop(encoded_columns,axis=1)\n",
    "Prueba=Prueba.drop(encoded_columns,axis=1)\n",
    "\n",
    "# Seleccionamos unicamente las variables de tipo float e integer\n",
    "Modelo=Modelo.select_dtypes(include=[\"float64\",\"int\"]).drop(\"fold\",axis=1)\n",
    "Prueba=Prueba.select_dtypes(include=[\"float64\",\"int\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b771c3",
   "metadata": {},
   "source": [
    "### 05 Búsqueda de hiperparámetros, ajuste del modelo y exportacion a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd29ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd62e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
