{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE PROCESAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 Instalación de paquetes a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-14T00:01:02.057082Z",
     "iopub.status.busy": "2022-08-14T00:01:02.056575Z",
     "iopub.status.idle": "2022-08-14T00:02:38.036845Z",
     "shell.execute_reply": "2022-08-14T00:02:38.035524Z",
     "shell.execute_reply.started": "2022-08-14T00:01:02.056980Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1659247144086,
     "user": {
      "displayName": "JAMIL MORENO GRIMALDO",
      "userId": "09852594977789940462"
     },
     "user_tz": 300
    },
    "id": "43e77989"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost==1.2.0\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install imblearn\n",
    "!pip install sklearn\n",
    "!pip install h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 Instalación y actualización de Java (para usar H2O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk --yes\n",
    "!apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 Importación de paquetes a usar e iniciación de H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 Procesamiento de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-14T00:05:09.643896Z",
     "iopub.status.busy": "2022-08-14T00:05:09.643236Z",
     "iopub.status.idle": "2022-08-14T01:03:54.348619Z",
     "shell.execute_reply": "2022-08-14T01:03:54.346981Z",
     "shell.execute_reply.started": "2022-08-14T00:05:09.643779Z"
    },
    "executionInfo": {
     "elapsed": 4103,
     "status": "ok",
     "timestamp": 1659247448708,
     "user": {
      "displayName": "JAMIL MORENO GRIMALDO",
      "userId": "09852594977789940462"
     },
     "user_tz": 300
    },
    "id": "f879e215",
    "outputId": "ada123e0-9872-45f2-b5ae-3197b67eba26"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"\"\n",
    "\n",
    "# Dataset: 01_suscriptora_202201_202204.csv\n",
    "df_1 = pd.read_csv(\"../input/data-final/01_suscriptora_202201_202204.csv\")\n",
    "pd.to_datetime(df_1['FECINGRESOCLIENTE'], format='%Y-%m-%d %H:%M:%S', errors = 'coerce')[23710] is pd.NaT\n",
    "df_1['TIPO_ADQ']=df_1['TIPO_ADQ'].map({'tipo1':1, 'tipo2':2})\n",
    "df_1['FECINGRESOCLIENTE'] = pd.to_datetime(df_1['FECINGRESOCLIENTE'], format='%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "df_1['FECACTIVACIONCONTRATO'] = pd.to_datetime(df_1['FECACTIVACIONCONTRATO'], format='%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "\n",
    "# Dataset: 02_adenda_202201_202204.csv\n",
    "df_2 = pd.read_csv(\"../input/data-final/02_adenda_202201_202204.csv\")\n",
    "\n",
    "# Dataset: 03_perfil_digital_202201_202204.csv\n",
    "df_3 = pd.read_csv(\"../input/data-final/03_perfil_digital_202201_202204.csv\")\n",
    "def format_group(x):\n",
    "    if x != None:\n",
    "        return int(x[6:])\n",
    "    return None\n",
    "df_3['GRUPO'].str.split('|', expand=True).applymap(format_group).max()\n",
    "for i in range(1,12):\n",
    "     df_3.loc[0, f'GRUPO_{i}'] = False\n",
    "        \n",
    "for index, value in df_3['GRUPO'].items():\n",
    "    group_list = [int(x[6:]) for x in value.split('|')]\n",
    "    for group in group_list:\n",
    "        df_3.loc[index, f'GRUPO_{group}'] = True;\n",
    "\n",
    "df_3 = df_3.fillna(0)\n",
    "\n",
    "for i in range (1,12):\n",
    "    df_3[f'GRUPO_{i}'].replace({False:0}, inplace=True)\n",
    "\n",
    "for i in range (1,12):\n",
    "    df_3[f'GRUPO_{i}'].replace({True:1}, inplace=True)\n",
    "    \n",
    "df_3.drop(columns=['GRUPO'], inplace=True)\n",
    "\n",
    "df_3['SCORECAT']=df_3['SCORECAT'].map({'bajo':1, 'medio':2, 'alto':3, 'muy alto':4})\n",
    "\n",
    "\n",
    "# Dataset: 03_perfil_digital_202201_202204.csv\n",
    "\n",
    "df_4 = pd.read_csv(\"../input/data-final/04_roaming_202201_202204.csv\")\n",
    "df_4 = df_4.drop(\"FECHATRAFICO\", axis=1)\n",
    "df_4[df_4['TIPOSERVICIO']=='TIPO2']['MINUTOS'].value_counts(normalize=True)\n",
    "\n",
    "filt = (df_4['TIPOSERVICIO'] == 'TIPO2') & (df_4['MINUTOS'] == 0)\n",
    "df_4.drop(index=df_4[filt].index, inplace=True)\n",
    "\n",
    "filt = (df_4['TIPOSERVICIO'] == 'TIPO1') & (df_4['GIGAS'] == 0)\n",
    "df_4.drop(index=df_4[filt].index, inplace=True)\n",
    "\n",
    "filt = (df_4['TIPOSERVICIO'] == 'TIPO3') & (df_4['MENSAJES'] == 0)\n",
    "df_4.drop(index=df_4[filt].index, inplace=True)\n",
    "\n",
    "for i in [\"GIGAS\", \"MINUTOS\", \"MENSAJES\"]:\n",
    "    b = df_4.groupby([\"PERIODO\", \"nro_telefono_hash\"]).agg({i: \"sum\"})\n",
    "    df_4 = df_4.drop(i, axis=1).merge(b, how='left', left_on=[\n",
    "        \"PERIODO\", \"nro_telefono_hash\"], right_on=[\"PERIODO\", \"nro_telefono_hash\"]).drop_duplicates()\n",
    "\n",
    "df_4.drop(columns=['TIPOSERVICIO'],inplace=True)\n",
    "\n",
    "# Dataset: 05_terminales_202201_202204.csv\n",
    "\n",
    "df_5 = pd.read_csv(\"../input/data-final/05_terminales_202201_202204.csv\")\n",
    "\n",
    "\n",
    "# Dataset: 06_trafico_202201_202204.csv\n",
    "\n",
    "df_6 = pd.read_csv(\"../input/data-final/06_trafico_202201_202204.csv\")\n",
    "\n",
    "# Dataset: 07_convergente_202201_202204.csv\n",
    "\n",
    "df_7 = pd.read_csv(\"../input/data-final/07_convergente_202201_202204.csv\")\n",
    "\n",
    "\n",
    "# Dataset: 08_target_202201_202203.csv\n",
    "\n",
    "df_8 = pd.read_csv(\"../input/data-final/08_target_202201_202203.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 Merge de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge llaves: NUMPERIODO y nro_telefono_hash\n",
    "merge_12 = df_1.merge(df_2,how=\"left\",left_on=['NUMPERIODO','nro_telefono_hash'],right_on=['NUMPERIODO','nro_telefono_hash'])\n",
    "merge_123 = merge_12.merge(df_3,how=\"left\",left_on=['NUMPERIODO','nro_telefono_hash'],right_on=['PERIODO','nro_telefono_hash'])\n",
    "merge_1234 = merge_123.merge(df_4,how=\"left\",left_on=['NUMPERIODO','nro_telefono_hash'],right_on=['PERIODO','nro_telefono_hash'])\n",
    "merge_12346 = merge_1234.merge(df_6,how=\"left\",left_on=['NUMPERIODO','nro_telefono_hash'],right_on=['NUMPERIODO','nro_telefono_hash'])\n",
    "merge_123468 = merge_12346.merge(df_8,how=\"left\",left_on=['NUMPERIODO','nro_telefono_hash'],right_on=['PERIODO','nro_telefono_hash'])\n",
    "\n",
    "# Merge llaves: NUMPERIODO y nro_telefono_hash\n",
    "merge_1234568 = merge_123468.merge(df5, how='right', left_on=[\"PERIODO\", \"nro_telefono_hash\"], right_on=[\"PERIODO\", \"nro_telefono_hash\"]).drop_duplicates()\n",
    "merge_12345678 = merge_1234568.merge(df7, how='left', left_on=[\"NUMPERIODO\", \"nro_documento_hash\"], right_on=[\"PERIODO\", \"nro_documento_hash\"]).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_12345678.to_csv(\"dataprefinal.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
