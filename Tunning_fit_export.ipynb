{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97412777",
   "metadata": {},
   "source": [
    "# TUNNIG, FIT AND EXPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decc974",
   "metadata": {},
   "source": [
    "### Búsqueda de hiperparámetros, ajuste del modelo y exportacion a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eefe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaremos el modelo y prueba que nos dio mejor resultado (usamos un mean encoding sin seed)\n",
    "Modelo = pd.read_csv(\"../input/data22222/Modelo (1).csv\")\n",
    "Prueba = pd.read_csv(\"../input/data22222/Prueba (1).csv\")\n",
    "X=Modelo.iloc[:,:-1]\n",
    "y=Modelo.iloc[:,-1].to_frame()\n",
    "Xp=Prueba.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5474cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un conjunto de hiperparametros a probar,estas configuraciones serán probadas y los resultados serán guardados en un csv nombrado partial_results.csv:\n",
    "\n",
    "params={'alpha': [0],\n",
    "        'colsample_bylevel': [1,2,3],\n",
    "        'colsample_bynode': [1],\n",
    "        'colsample_bytree': [0.3,0.35,0.4],\n",
    "        'eval_metric': 'auc',\n",
    "        'gamma': [0.8,0.9,1],\n",
    "        'lambda': [1],\n",
    "        'learning_rate': [0.0008],\n",
    "        'max_delta_step': [0],\n",
    "        'max_depth': [19], \n",
    "        'min_child_weight': [40],\n",
    "        'n_estimators': [10000],\n",
    "        'scale_pos_weight': [32.26]}    #Usado para combatir el desbalanceo de datos, el valor es la proporción de 0 respecto a 1 en Target\n",
    "\n",
    "\n",
    "# Creamos un csv denominado partial_results.csv:\n",
    "def create_partial_results_csv():\n",
    "    df = pd.DataFrame(columns=['alpha', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'eval_metric', 'gamma', 'lambda', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'n_estimators', 'scale_pos_weight', 'best_score', 'minutes', 'seconds', 'params'])\n",
    "    df.to_csv('partial_results.csv', index=False)\n",
    "create_partial_results_csv()\n",
    "\n",
    "#Creamos un kfold estratificado con 5 grupos que seran usados para probar el perfomance del modelo en un grid search:\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)  \n",
    "\n",
    "# Definimos un grid search:\n",
    "def grid_search(params, reg=XGBClassifier(booster='gbtree', objective='binary:logistic',missing=-999.0,random_state=2,n_jobs=-1,tree_method='gpu_hist',eval_metric='auc')):\n",
    "    grid_reg = GridSearchCV(reg, params, scoring='roc_auc', cv=kfold)\n",
    "    grid_reg.fit(X, y.values.ravel())\n",
    "    global best_params \n",
    "    best_params = grid_reg.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = grid_reg.best_score_\n",
    "    print(\"Best score:\", best_score)\n",
    "    return best_params, best_score\n",
    "\n",
    "# Creamos una lista que guardara cada combinación de hiperparametros con el respectivo score(auc) que obtienen:\n",
    "def get_result_list(params):\n",
    "    start = time.time()\n",
    "    par, sco = grid_search(params)\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    m = int(t//60)\n",
    "    s = round(t%60,2)\n",
    "    l = list(par.values())\n",
    "    l.append(sco)\n",
    "    l.append(m)\n",
    "    l.append(s)\n",
    "    l.append(par)\n",
    "    return l;\n",
    "\n",
    "#Escribimos en el csv cada objeto de la lista creada (combinación de parámetros con score)\n",
    "from csv import writer\n",
    "def write_list_in_csv(l, csv_name='partial_results.csv'):\n",
    "    with open(csv_name, 'a') as f_object:\n",
    "        writer_object = writer(f_object)\n",
    "        writer_object.writerow(l)\n",
    "        f_object.close()\n",
    "\n",
    "#Definimos una función que devuelve los parametros de los csv creados por índice\n",
    "def get_params_from_csv(index, csv_name='partial_results.csv'):\n",
    "    # Devuelve un diccionario con los parametros de una fila de partial_results.csv\n",
    "    dfpr = pd.read_csv(csv_name)\n",
    "    foo = dfpr['params'][index]\n",
    "    import ast\n",
    "    return ast.literal_eval(foo)\n",
    "\n",
    "# Devuelve un csv listo para mandar a kaggle usando los parametros de params (dict)\n",
    "def export_send_csv(params, name='envioJ.csv'):\n",
    "    mod=XGBClassifier(booster='gbtree', objective='binary:logistic',missing=-999.0,random_state=3,n_jobs=-1,tree_method='gpu_hist',eval_metric='auc')\n",
    "    mod.set_params(**params)\n",
    "\n",
    "    start = time.time()\n",
    "    mod.fit(X,y)\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print(f'Demoro: {int(t//60)} minutos y {round(t%60,2)} segundos')\n",
    "    prediccion_final=mod.predict_proba(Xp)[:,1]\n",
    "    kek=pd.DataFrame(prediccion_final)\n",
    "    kek.rename(columns={0:'TARGET'}, inplace=True)\n",
    "    toconcat=[go[go[\"NUMPERIODO\"]==202204][[\"nro_telefono_hash\"]].reset_index(drop=True),kek.reset_index(drop=True)]\n",
    "    ya=pd.concat(toconcat,axis=1,ignore_index=True)\n",
    "    ya.rename(columns={0:\"nro_telefono_hash\",1:'TARGET'}, inplace=True)\n",
    "    ya.to_csv(name, index=False)\n",
    "\n",
    "\n",
    "\n",
    "write_list_in_csv(get_result_list(params))\n",
    "da = pd.read_csv('partial_results.csv')\n",
    "# Observamos las combinaciones de hiperparametros con mejores puntajes (revisamos el indice de 5 los mejores modelos)\n",
    "da.sort_values(by='best_score', ascending=False).head(20)\n",
    "#U sando esos indices obtenemos sus parametros\n",
    "get_params_from_csv(0, csv_name='partial_results.csv'):\n",
    "\n",
    "# Crea un csv listo para mandar a kaggle con alguna de las filas del partial_results.csv\n",
    "export_send_csv(get_params_from_csv(32), 'envioJV32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f150ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
